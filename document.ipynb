{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yWXNKLe0eHi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas: For data manipulation.\n",
        "Numpy: For numerical operations.\n",
        "re: For regular expressions.\n",
        "nltk: For text processing tasks like tokenization, stopwords removal, stemming, and lemmatization.\n",
        "scikit-learn: For feature extraction (TF-IDF), data splitting, and label encoding.\n",
        "keras: For building and training the neural network model.\n",
        "joblib: For saving and loading model artifacts."
      ],
      "metadata": {
        "id": "nUgVVhVt0ehC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "PyKrkjV40m9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset containing hotel reviews and their ratings.\n"
      ],
      "metadata": {
        "id": "s3RHHlSS0qWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"hotel_reviews.csv\")\n"
      ],
      "metadata": {
        "id": "iyTwQxaU0qks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert numerical ratings to categorical sentiment labels."
      ],
      "metadata": {
        "id": "vj-OpCpt0qyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rating_to_sentiment(rating):\n",
        "    if rating in [1, 2]:\n",
        "        return 'Negative'\n",
        "    elif rating == 3:\n",
        "        return 'Neutral'\n",
        "    else:\n",
        "        return 'Positive'\n",
        "\n",
        "df['Sentiment'] = df['Rating'].apply(rating_to_sentiment)\n"
      ],
      "metadata": {
        "id": "8UjgSEBq0q63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove HTML tags, punctuation, and convert text to lowercase."
      ],
      "metadata": {
        "id": "ybZpEwz20rDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df['Review'].apply(lambda x: re.sub(\"<.*?>\", \"\", x))\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: re.sub('[^\\w\\s]', \"\", x))\n",
        "df['clean_text'] = df['clean_text'].str.lower()"
      ],
      "metadata": {
        "id": "I_rUruOR09Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download necessary NLTK resources for tokenization, stopwords, and lemmatization."
      ],
      "metadata": {
        "id": "Ed_vLGsH09gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "DV9B4PYo0rKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the text, remove stopwords, and apply stemming and lemmatization for normalization."
      ],
      "metadata": {
        "id": "3jLNogpf1LfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "lemma = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "df['tokenize_text'] = df['clean_text'].apply(lambda y: word_tokenize(y))\n",
        "df['filtered_text'] = df['tokenize_text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "df['stem_text'] = df['filtered_text'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
        "df['lemma_text'] = df['filtered_text'].apply(lambda x: [lemma.lemmatize(word) for word in x])\n"
      ],
      "metadata": {
        "id": "XgmErn1C1MdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data by splitting it into training and test sets.\n"
      ],
      "metadata": {
        "id": "FFwn1M991My_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df['stem_text'].apply(lambda x: ' '.join(x))\n",
        "y = df['Sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "qJ5kK7L51NC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform text data into TF-IDF features for the model.\n"
      ],
      "metadata": {
        "id": "IUdGu0Sj1NMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf1 = TfidfVectorizer()\n",
        "X_train = tfidf1.fit_transform(X_train)\n",
        "X_test = tfidf1.transform(X_test)\n"
      ],
      "metadata": {
        "id": "kUfgANNw1NYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode sentiment labels as integers and then convert them to one-hot encoded vectors."
      ],
      "metadata": {
        "id": "kj5yotZG1Nfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = to_categorical(y_test, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "Ln2ssYXM1hfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a neural network with dense layers and ReLU activations.\n",
        "Compile and train the model, and save it along with the TF-IDF vectorizer using joblib"
      ],
      "metadata": {
        "id": "5RqahzEj1hn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "Model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "Model.fit(X_train, y_train, epochs=1, batch_size=32)\n",
        "joblib.dump(Model,'Model.pkl')\n",
        "joblib.dump(tfidf1, 'tfidf1.pkl')\n"
      ],
      "metadata": {
        "id": "Jw1QvDvb1hvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the trained model and TF-IDF vectorizer.\n"
      ],
      "metadata": {
        "id": "SBsnqXet1_NS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "import streamlit as st\n",
        "\n",
        "Model = joblib.load('Model.pkl')\n",
        "tfidf1_vectorizer = joblib.load('tfidf1.pkl')\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n"
      ],
      "metadata": {
        "id": "n0AneCdN1_pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to preprocess input text and predict sentiment using the model."
      ],
      "metadata": {
        "id": "pjErw9HW1_42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices_to_sentiments = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
        "\n",
        "def predict_sentiment(review):\n",
        "    cleaned_review = re.sub('<.*?>', \"\", review)\n",
        "    cleaned_review = re.sub(r'[^\\w\\s]', '', cleaned_review)\n",
        "    cleaned_review = cleaned_review.lower()\n",
        "    tokenized_review = word_tokenize(cleaned_review)\n",
        "    filter_review = [word for word in tokenized_review if word not in stop_words]\n",
        "    stemmed_review = [stemmer.stem(word) for word in filter_review]\n",
        "    tfidf_review = tfidf1_vectorizer.transform([' '.join(stemmed_review)])\n",
        "\n",
        "    if tfidf_review.nnz == 0:\n",
        "        return 'Unable to predict'\n",
        "\n",
        "    sentiment_prediction = Model.predict(tfidf_review)\n",
        "    predicted_class_index = np.argmax(sentiment_prediction, axis=1)\n",
        "\n",
        "    return class_indices_to_sentiments.get(predicted_class_index[0], 'Unable to predict')\n"
      ],
      "metadata": {
        "id": "tBPpmey-2AG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a simple web application using Streamlit for user interaction."
      ],
      "metadata": {
        "id": "7R_jIzR92APn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "st.title('Hotel Review Sentiment Prediction:')\n",
        "review_to_predict = st.text_area('Enter your review:')\n",
        "if st.button('Predict Sentiment:'):\n",
        "    predicted_sentiment = predict_sentiment(review_to_predict)\n",
        "    st.write('Predicted sentiment:', predicted_sentiment)\n"
      ],
      "metadata": {
        "id": "1fMzuAfO2AaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the Jupyter notebook to a Python script using nbconvert"
      ],
      "metadata": {
        "id": "XNprh9Mu2XAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ipynb-py-convert hotel_reviewAnalysis.ipynb hotelReviewAnalysis.py\n"
      ],
      "metadata": {
        "id": "DkB27pwg2XTK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}