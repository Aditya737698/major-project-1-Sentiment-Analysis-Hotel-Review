{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6cfd87-9ff6-4352-bd63-6b6f35815c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61137fa-a037-47e5-ac80-0de1e0ad23d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\w'\n",
      "/var/folders/xm/z137nvsd3plc31302pmtj3640000gn/T/ipykernel_7716/3963718805.py:14: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  df['clean_text'] = df['clean_text'].apply(lambda x: re.sub('[^\\w\\s]', \"\", x))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"hotel_reviews.csv\")\n",
    "\n",
    "def rating_to_sentiment(rating):\n",
    "    if rating in [1, 2]:\n",
    "        return 'Negative'\n",
    "    elif rating == 3:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "\n",
    "df['Sentiment'] = df['Rating'].apply(rating_to_sentiment)\n",
    "\n",
    "df['clean_text'] = df['Review'].apply(lambda x: re.sub(\"<.*?>\", \"\", x))\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: re.sub('[^\\w\\s]', \"\", x))\n",
    "df['clean_text'] = df['clean_text'].str.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b29dcb-ec77-4850-befd-2a5e07e46280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adityapatil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adityapatil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/adityapatil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['tokenize_text'] = df['clean_text'].apply(lambda y: word_tokenize(y))\n",
    "df['filtered_text'] = df['tokenize_text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df['stem_text'] = df['filtered_text'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "df['lemma_text'] = df['filtered_text'].apply(lambda x: [lemma.lemmatize(word) for word in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4f6ff4-1ada-4765-9151-4cc1c5494b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - accuracy: 0.7949 - loss: 0.5829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf1.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['stem_text'].apply(lambda x: ' '.join(x))\n",
    "y = df['Sentiment']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2)\n",
    "\n",
    "tfidf1 = TfidfVectorizer()\n",
    "X_train = tfidf1.fit_transform(X_train)\n",
    "X_test = tfidf1.transform(X_test)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "num_classes = len(np.unique(y_train))  \n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "Model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "Model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "Model.fit(X_train, y_train, epochs=1, batch_size=32)  \n",
    "joblib.dump(Model,'Model.pkl')\n",
    "joblib.dump(tfidf1, 'tfidf1.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e21d11e3-f8d5-48d9-be3a-ce1f3fe5f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 20:05:27.498 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "import streamlit as st\n",
    "\n",
    "Model = joblib.load('Model.pkl')\n",
    "tfidf1_vectorizer = joblib.load('tfidf1.pkl')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "class_indices_to_sentiments = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
    "\n",
    "def predict_sentiment(review):\n",
    "    cleaned_review = re.sub('<.*?>', \"\", review)\n",
    "    cleaned_review = re.sub(r'[^\\w\\s]', '', cleaned_review)\n",
    "    cleaned_review = cleaned_review.lower()\n",
    "    tokenized_review = word_tokenize(cleaned_review)\n",
    "    filter_review = [word for word in tokenized_review if word not in stop_words]\n",
    "    stemmed_review = [stemmer.stem(word) for word in filter_review]\n",
    "    tfidf_review = tfidf1_vectorizer.transform([' '.join(stemmed_review)])\n",
    "    \n",
    "    if tfidf_review.nnz == 0:\n",
    "        return 'Unable to predict'\n",
    "\n",
    "    sentiment_prediction = Model.predict(tfidf_review)\n",
    "    predicted_class_index = np.argmax(sentiment_prediction, axis=1)\n",
    "\n",
    "    return class_indices_to_sentiments.get(predicted_class_index[0], 'Unable to predict')\n",
    "\n",
    "st.title('Hotel Review Sentiment Prediction:')\n",
    "review_to_predict = st.text_area('Enter your review:')\n",
    "if st.button('Predict Sentiment:'):\n",
    "    predicted_sentiment = predict_sentiment(review_to_predict)\n",
    "    st.write('Predicted sentiment:', predicted_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac39ca27-29f4-45bf-9fbf-07aaab131a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ipynb-py-convert hotel_reviewAnalysis.ipynb hotelReviewAnalysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a293550-4ba3-42a7-84e5-3ef9af8f0a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.8.75:8502\u001b[0m\n",
      "\u001b[0m\n",
      "/Users/adityapatil/Jupyter/hotelReviewAnalysis.py:33: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  df['clean_text'] = df['clean_text'].apply(lambda x: re.sub('[^\\w\\s]', \"\", x))\n"
     ]
    }
   ],
   "source": [
    "!streamlit run hotelReviewAnalysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e45f5a-1809-495a-a91d-fc03b36acf68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
